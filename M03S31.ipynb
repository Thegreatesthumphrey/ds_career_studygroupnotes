{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STUDY GROUP - M03S31\n",
    "## Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objectives\n",
    "You will be able to:\n",
    "* understand PAC theroy\n",
    "* explain entropy and information gain and the relationship between them\n",
    "* explain how decision trees work\n",
    "* introduction to hyperparameters and hyperparamenter tuning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PAC Theory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probably Approximatly Correct (PAC) Theory - mathematical definition of how machine learning works\n",
    "\n",
    "intuition behind PAC theory: there is a function h learned from training data that approximates the true function f within an acceptable error, theoretical framework to justify theory of machine learning (i.e. train/test split)\n",
    "\n",
    "**2 Factors for Success of PAC Theory**\n",
    "\n",
    "failure probability - \n",
    "\n",
    "function approximation - \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How PAC relates to Machine Learning**\n",
    "\n",
    "PAC uses the term 'hypothesis',whereas ML literature normally uses the term 'model'. So we have seen that Machine learning starts with some data, (xi,yi) and we want to find a hypothesis (or model) that will, given the inputs xi return yi or something very close. More importantly given new data x̃ the model will predict the corresponding ỹ.\n",
    "\n",
    "A model that was created using some (out of many examples) of data do not accurately reflect that data set, but can be accurate on any future data sets. The two important points are that we cannot predict new data with 100% accuracy. There is also the possibility that the one or more examples are poor and do not explain much.\n",
    "\n",
    "We present our data to the learner and let it make an attempt to learn the hypothesis function. At discrete stages ,we then look at the error as the difference between real and hypothesis function outputs. A problem is called learnable if we can reduce this error within acceptable bounds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entropy & Information Gain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "entropy - measure of chaos/uncertainty/dirtyness\n",
    "   * entropy of a variable - measure information contained in variable, messiness of data \n",
    "   \n",
    "Shannon's entropy -\n",
    "\n",
    "Do we want entropy to increase or decrease when making splits in our decision tree? Why? - decrease so that information gain increases\n",
    "\n",
    "information gain - measure of difference in entroy from before and after the split, measure of reduction of uncertainty; inversely proportional to entropy \n",
    "   * IG ~= 1/E"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why is hyperparameter tuning important? - can reduce overfit in model, can reduce E/increase IG, improve accuracy of the model\n",
    "\n",
    "What is a hyperparameter? - parameter that must be set/known before algorithm execution (k in KNN, L1/L2 in linreg, C in logreg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CART for Regresssion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
