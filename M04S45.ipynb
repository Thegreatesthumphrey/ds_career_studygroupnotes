{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STUDY GROUP - M04S45\n",
    "## NLP with Word Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objectives\n",
    "\n",
    "You will be able to:\n",
    "* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Embeddings\n",
    "\n",
    "- vectorization technique\n",
    "- provides much denser (shorter) information compared to count vectorization or TF-IDF vectorization \n",
    "- captures sematic relationships\n",
    "- smaller vector size due to window selection rather than features=len(corpus)\n",
    "- preprocessing to remove stopwords before Word2Vec\n",
    "\n",
    "how you can use them to model the semantic meanings of words in a high-dimensional embedding space! Word embeddings use similarity metrics to represent how two words relate to each other. \n",
    "\n",
    "Word Embeddings are a type of vectorization strategy that computes word vectors from a text corpus by training a neural network, which results in a high-dimensional embedding space, where each word is in the corpus is a unique vector in that space. In this embedding space, the position of the vector relative to the other vectors captures semantic meaning.\n",
    "\n",
    "Because the words are all embeddded in the same high-dimensional space, we can use the same similarity metrics we've used before, such as things like Cosine Similarity or even Euclidean Distance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec\n",
    "\n",
    "Word2Vec is just another Deep Neural Network, that looks at sequences of words and words that are often used in similar contexts (or close to each other in sentences), which creates word embeddings\n",
    "\n",
    "mean word embeddings - average Word2Vec of all words in a text sample, condenses dimensions to allow for use in supervised learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification with Word Embeddings\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
